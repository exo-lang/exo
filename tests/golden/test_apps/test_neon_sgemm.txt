
#pragma once
#ifndef TEST_CASE_H
#define TEST_CASE_H

#ifdef __cplusplus
extern "C" {
#endif


#include <stdint.h>
#include <stdbool.h>

// Compiler feature macros adapted from Hedley (public domain)
// https://github.com/nemequ/hedley

#if defined(__has_builtin)
#  define EXO_HAS_BUILTIN(builtin) __has_builtin(builtin)
#else
#  define EXO_HAS_BUILTIN(builtin) (0)
#endif

#if EXO_HAS_BUILTIN(__builtin_assume)
#  define EXO_ASSUME(expr) __builtin_assume(expr)
#elif EXO_HAS_BUILTIN(__builtin_unreachable)
#  define EXO_ASSUME(expr) \
      ((void)((expr) ? 1 : (__builtin_unreachable(), 1)))
#else
#  define EXO_ASSUME(expr) ((void)(expr))
#endif


#include <stdio.h>
#include <stdlib.h>

#ifndef EXO_WIN_1F32
#define EXO_WIN_1F32
struct exo_win_1f32{
    float * const data;
    const int_fast32_t strides[1];
};
#endif
#ifndef EXO_WIN_1F32C
#define EXO_WIN_1F32C
struct exo_win_1f32c{
    const float * const data;
    const int_fast32_t strides[1];
};
#endif
#ifndef EXO_WIN_2F32
#define EXO_WIN_2F32
struct exo_win_2f32{
    float * const data;
    const int_fast32_t strides[2];
};
#endif
#ifndef EXO_WIN_2F32C
#define EXO_WIN_2F32C
struct exo_win_2f32c{
    const float * const data;
    const int_fast32_t strides[2];
};
#endif
// sgemm_exo(
//     M : size,
//     N : size,
//     K : size,
//     A : f32[M, K] @DRAM,
//     B : f32[K, N] @DRAM,
//     C : f32[M, N] @DRAM
// )
void sgemm_exo( void *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, const float* A, const float* B, float* C );



#ifdef __cplusplus
}
#endif
#endif  // TEST_CASE_H

#include "test_case.h"

#include <arm_neon.h>
// neon_microkernel(
//     K : size,
//     A : [f32][4, K] @DRAM,
//     B : [f32][K, 16] @DRAM,
//     C : [f32][4, 16] @DRAM
// )
static void neon_microkernel( void *ctxt, int_fast32_t K, struct exo_win_2f32c A, struct exo_win_2f32c B, struct exo_win_2f32 C );


/* relying on the following instruction..."
neon_broadcast_4xf32(dst,src)
{dst_data} = vld1q_dup_f32(&{src_data});
*/
// neon_microkernel(
//     K : size,
//     A : [f32][4, K] @DRAM,
//     B : [f32][K, 16] @DRAM,
//     C : [f32][4, 16] @DRAM
// )
static void neon_microkernel( void *ctxt, int_fast32_t K, struct exo_win_2f32c A, struct exo_win_2f32c B, struct exo_win_2f32 C ) {
EXO_ASSUME(K >= 1);
// assert stride(A, 1) == 1
// assert stride(B, 1) == 1
// assert stride(C, 1) == 1
float32x4_t C_reg[4][4];
for (int_fast32_t i = 0; i < 4; i++) {
  for (int_fast32_t jo = 0; jo < 4; jo++) {
    C_reg[i][jo] = vld1q_f32(&C.data[(i) * (C.strides[0]) + 4 * jo]);
  }
}
for (int_fast32_t k = 0; k < K; k++) {
  float32x4_t A_vec;
  for (int_fast32_t i = 0; i < 4; i++) {
    A_vec = vld1q_dup_f32(&A.data[(i) * (A.strides[0]) + k]);
  }
  float32x4_t B_vec;
  for (int_fast32_t jo = 0; jo < 4; jo++) {
    B_vec = vld1q_f32(&B.data[(k) * (B.strides[0]) + 4 * jo]);
  }
  for (int_fast32_t i = 0; i < 4; i++) {
    for (int_fast32_t jo = 0; jo < 4; jo++) {
      C_reg[i][jo] = vmlaq_f32(C_reg[i][jo], A_vec, B_vec);
    }
  }
}
for (int_fast32_t i = 0; i < 4; i++) {
  for (int_fast32_t jo = 0; jo < 4; jo++) {
    vst1q_f32(&C.data[(i) * (C.strides[0]) + 4 * jo], C_reg[i][jo]);
  }
}
}


/* relying on the following instruction..."
neon_vfmadd_4xf32_4xf32(dst,lhs,rhs)
{dst_data} = vmlaq_f32({dst_data}, {lhs_data}, {rhs_data});
*/

/* relying on the following instruction..."
neon_vld_4xf32(dst,src)
{dst_data} = vld1q_f32(&{src_data});
*/

/* relying on the following instruction..."
neon_vst_4xf32(dst,src)
vst1q_f32(&{dst_data}, {src_data});
*/
// sgemm_exo(
//     M : size,
//     N : size,
//     K : size,
//     A : f32[M, K] @DRAM,
//     B : f32[K, N] @DRAM,
//     C : f32[M, N] @DRAM
// )
void sgemm_exo( void *ctxt, int_fast32_t M, int_fast32_t N, int_fast32_t K, const float* A, const float* B, float* C ) {
EXO_ASSUME(M >= 1);
EXO_ASSUME(N >= 1);
EXO_ASSUME(K >= 1);
// assert stride(A, 1) == 1
// assert stride(B, 1) == 1
// assert stride(C, 1) == 1
float *Atile = (float*) malloc(64 * 64 * sizeof(*Atile));
float *Btile = (float*) malloc(64 * 64 * sizeof(*Btile));
for (int_fast32_t ko = 0; ko < ((K) / (64)); ko++) {
  for (int_fast32_t io = 0; io < ((M) / (64)); io++) {
    for (int_fast32_t i0 = 0; i0 < 64; i0++) {
      for (int_fast32_t i1 = 0; i1 < 64; i1++) {
        Atile[i0 * 64 + i1] = A[(i0 + 64 * io) * K + i1 + 64 * ko];
      }
    }
    for (int_fast32_t jo = 0; jo < ((N) / (64)); jo++) {
      for (int_fast32_t i0 = 0; i0 < 64; i0++) {
        for (int_fast32_t i1 = 0; i1 < 64; i1++) {
          Btile[i0 * 64 + i1] = B[(i0 + 64 * ko) * N + i1 + 64 * jo];
        }
      }
      for (int_fast32_t im = 0; im < 16; im++) {
        for (int_fast32_t jm = 0; jm < 4; jm++) {
          neon_microkernel(ctxt,64,(struct exo_win_2f32c){ &Atile[(4 * im) * (64)], { 64, 1 } },(struct exo_win_2f32c){ &Btile[16 * jm], { 64, 1 } },(struct exo_win_2f32){ &C[(4 * im + 64 * io) * N + 16 * jm + 64 * jo], { N, 1 } });
        }
      }
    }
  }
}
free(Btile);
free(Atile);
for (int_fast32_t ko = 0; ko < ((K) / (64)); ko++) {
  for (int_fast32_t io = 0; io < ((M) / (64)); io++) {
    for (int_fast32_t jm = 0; jm < ((N) / (16)) % 4; jm++) {
      for (int_fast32_t im = 0; im < 16; im++) {
        neon_microkernel(ctxt,64,(struct exo_win_2f32c){ &A[(4 * im + 64 * io) * K + 64 * ko], { K, 1 } },(struct exo_win_2f32c){ &B[(64 * ko) * N + 16 * (jm + (N / 64) * 4)], { N, 1 } },(struct exo_win_2f32){ &C[(4 * im + 64 * io) * N + 16 * (jm + (N / 64) * 4)], { N, 1 } });
      }
    }
  }
  for (int_fast32_t jo = 0; jo < ((N) / (16)); jo++) {
    for (int_fast32_t im = 0; im < ((M) / (4)) % 16; im++) {
      neon_microkernel(ctxt,64,(struct exo_win_2f32c){ &A[(4 * (im + (M / 64) * 16)) * K + 64 * ko], { K, 1 } },(struct exo_win_2f32c){ &B[(64 * ko) * N + 16 * jo], { N, 1 } },(struct exo_win_2f32){ &C[(4 * (im + (M / 64) * 16)) * N + 16 * jo], { N, 1 } });
    }
  }
}
for (int_fast32_t io = 0; io < ((M) / (4)); io++) {
  for (int_fast32_t jo = 0; jo < ((N) / (16)); jo++) {
    for (int_fast32_t ii = 0; ii < 4; ii++) {
      for (int_fast32_t ji = 0; ji < 16; ji++) {
        if (K % 64 > 0) {
          for (int_fast32_t ki = 0; ki < K % 64; ki++) {
            C[(ii + 4 * io) * N + ji + 16 * jo] += A[(ii + 4 * io) * K + ki + (K / 64) * 64] * B[(ki + (K / 64) * 64) * N + ji + 16 * jo];
          }
        }
      }
    }
  }
}
for (int_fast32_t io = 0; io < ((M) / (4)); io++) {
  for (int_fast32_t ii = 0; ii < 4; ii++) {
    if (N % 16 > 0) {
      for (int_fast32_t ji = 0; ji < N % 16; ji++) {
        for (int_fast32_t k = 0; k < K; k++) {
          C[(ii + 4 * io) * N + ji + (N / 16) * 16] += A[(ii + 4 * io) * K + k] * B[k * N + ji + (N / 16) * 16];
        }
      }
    }
  }
}
if (M % 4 > 0) {
  for (int_fast32_t ii = 0; ii < M % 4; ii++) {
    for (int_fast32_t j = 0; j < N; j++) {
      for (int_fast32_t k = 0; k < K; k++) {
        C[(ii + (M / 4) * 4) * N + j] += A[(ii + (M / 4) * 4) * K + k] * B[k * N + j];
      }
    }
  }
}
}

